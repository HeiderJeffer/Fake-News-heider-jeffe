{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "758c06e5-3851-417f-9ddf-48da81d69850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Besides scikit-learn, TensorFlow is another tool that \n",
    "# we can use for machine learning projects. For similar reasons, \n",
    "# there is also a dataset API for TensorFlow that gives you \n",
    "# the dataset in a format that works best with TensorFlow. \n",
    "# Unlike scikit-learn, the API is not part of the standard \n",
    "# TensorFlow package. You need to install it using the command:\n",
    "\n",
    "# pip install tensorflow-datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a7023e-dfcf-4d7a-88cf-47c7caec4567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract_reasoning', 'accentdb', 'aeslc', 'aflw2k3d', 'ag_news_subset', 'ai2_arc', 'ai2_arc_with_ir', 'amazon_us_reviews', 'anli', 'answer_equivalence', 'arc', 'asqa', 'asset', 'assin2', 'bair_robot_pushing_small', 'bccd', 'beans', 'bee_dataset', 'beir', 'big_patent', 'bigearthnet', 'billsum', 'binarized_mnist', 'binary_alpha_digits', 'ble_wind_field', 'blimp', 'booksum', 'bool_q', 'bucc', 'c4', 'c4_wsrs', 'caltech101', 'caltech_birds2010', 'caltech_birds2011', 'cardiotox', 'cars196', 'cassava', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'cfq', 'cherry_blossoms', 'chexpert', 'cifar10', 'cifar100', 'cifar100_n', 'cifar10_1', 'cifar10_corrupted', 'cifar10_n', 'citrus_leaves', 'cityscapes', 'civil_comments', 'clevr', 'clic', 'clinc_oos', 'cmaterdb', 'cnn_dailymail', 'coco', 'coco_captions', 'coil100', 'colorectal_histology', 'colorectal_histology_large', 'common_voice', 'conll2002', 'conll2003', 'controlled_noisy_web_labels', 'coqa', 'cos_e', 'cosmos_qa', 'covid19', 'covid19sum', 'crema_d', 'criteo', 'cs_restaurants', 'curated_breast_imaging_ddsm', 'cycle_gan', 'd4rl_adroit_door', 'd4rl_adroit_hammer', 'd4rl_adroit_pen', 'd4rl_adroit_relocate', 'd4rl_antmaze', 'd4rl_mujoco_ant', 'd4rl_mujoco_halfcheetah', 'd4rl_mujoco_hopper', 'd4rl_mujoco_walker2d', 'dart', 'davis', 'deep1b', 'deep_weeds', 'definite_pronoun_resolution', 'dementiabank', 'diabetic_retinopathy_detection', 'diamonds', 'div2k', 'dmlab', 'doc_nli', 'dolphin_number_word', 'domainnet', 'downsampled_imagenet', 'drop', 'dsprites', 'dtd', 'duke_ultrasound', 'e2e_cleaned', 'efron_morris75', 'emnist', 'eraser_multi_rc', 'esnli', 'eurosat', 'fashion_mnist', 'flic', 'flores', 'food101', 'forest_fires', 'fuss', 'gap', 'geirhos_conflict_stimuli', 'gem', 'genomics_ood', 'german_credit_numeric', 'gigaword', 'glove100_angular', 'glue', 'goemotions', 'gov_report', 'gpt3', 'gref', 'groove', 'grounded_scan', 'gsm8k', 'gtzan', 'gtzan_music_speech', 'hellaswag', 'higgs', 'hillstrom', 'horses_or_humans', 'howell', 'i_naturalist2017', 'i_naturalist2018', 'i_naturalist2021', 'imagenet2012', 'imagenet2012_corrupted', 'imagenet2012_fewshot', 'imagenet2012_multilabel', 'imagenet2012_real', 'imagenet2012_subset', 'imagenet_a', 'imagenet_lt', 'imagenet_r', 'imagenet_resized', 'imagenet_sketch', 'imagenet_v2', 'imagenette', 'imagewang', 'imdb_reviews', 'irc_disentanglement', 'iris', 'istella', 'kddcup99', 'kitti', 'kmnist', 'laion400m', 'lambada', 'lfw', 'librispeech', 'librispeech_lm', 'libritts', 'ljspeech', 'lm1b', 'locomotion', 'lost_and_found', 'lsun', 'lvis', 'malaria', 'math_dataset', 'math_qa', 'mctaco', 'media_sum', 'mlqa', 'mnist', 'mnist_corrupted', 'movie_lens', 'movie_rationales', 'movielens', 'moving_mnist', 'mrqa', 'mslr_web', 'mt_opt', 'mtnt', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'natural_instructions', 'natural_questions', 'natural_questions_open', 'newsroom', 'nsynth', 'nyu_depth_v2', 'ogbg_molpcba', 'omniglot', 'open_images_challenge2019_detection', 'open_images_v4', 'openbookqa', 'opinion_abstracts', 'opinosis', 'opus', 'oxford_flowers102', 'oxford_iiit_pet', 'para_crawl', 'pass', 'patch_camelyon', 'paws_wiki', 'paws_x_wiki', 'penguins', 'pet_finder', 'pg19', 'piqa', 'places365_small', 'placesfull', 'plant_leaves', 'plant_village', 'plantae_k', 'protein_net', 'q_re_cc', 'qa4mre', 'qasc', 'quac', 'quality', 'quickdraw_bitmap', 'race', 'radon', 'reddit', 'reddit_disentanglement', 'reddit_tifu', 'ref_coco', 'resisc45', 'rlu_atari', 'rlu_atari_checkpoints', 'rlu_atari_checkpoints_ordered', 'rlu_control_suite', 'rlu_dmlab_explore_object_rewards_few', 'rlu_dmlab_explore_object_rewards_many', 'rlu_dmlab_rooms_select_nonmatching_object', 'rlu_dmlab_rooms_watermaze', 'rlu_dmlab_seekavoid_arena01', 'rlu_locomotion', 'rlu_rwrl', 'robomimic_ph', 'robonet', 'robosuite_panda_pick_place_can', 'rock_paper_scissors', 'rock_you', 's3o4d', 'salient_span_wikipedia', 'samsum', 'savee', 'scan', 'scene_parse150', 'schema_guided_dialogue', 'sci_tail', 'scicite', 'scientific_papers', 'scrolls', 'sentiment140', 'shapes3d', 'sift1m', 'simpte', 'siscore', 'smallnorb', 'smartwatch_gestures', 'snli', 'so2sat', 'speech_commands', 'spoken_digit', 'squad', 'squad_question_generation', 'stanford_dogs', 'stanford_online_products', 'star_cfq', 'starcraft_video', 'stl10', 'story_cloze', 'summscreen', 'sun397', 'super_glue', 'svhn_cropped', 'symmetric_solids', 'tao', 'tatoeba', 'ted_hrlr_translate', 'ted_multi_translate', 'tedlium', 'tf_flowers', 'the300w_lp', 'tiny_shakespeare', 'titanic', 'trec', 'trivia_qa', 'tydi_qa', 'uc_merced', 'ucf101', 'unified_qa', 'universal_dependencies', 'unnatural_instructions', 'user_libri_audio', 'user_libri_text', 'vctk', 'visual_domain_decathlon', 'voc', 'voxceleb', 'voxforge', 'waymo_open_dataset', 'web_graph', 'web_nlg', 'web_questions', 'wider_face', 'wiki40b', 'wiki_auto', 'wiki_bio', 'wiki_dialog', 'wiki_table_questions', 'wiki_table_text', 'wikiann', 'wikihow', 'wikipedia', 'wikipedia_toxicity_subtypes', 'wine_quality', 'winogrande', 'wit', 'wit_kaggle', 'wmt13_translate', 'wmt14_translate', 'wmt15_translate', 'wmt16_translate', 'wmt17_translate', 'wmt18_translate', 'wmt19_translate', 'wmt_t2t_translate', 'wmt_translate', 'wordnet', 'wsc273', 'xnli', 'xquad', 'xsum', 'xtreme_pawsx', 'xtreme_pos', 'xtreme_s', 'xtreme_xnli', 'yahoo_ltrc', 'yelp_polarity_reviews', 'yes_no', 'youtube_vis']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds \n",
    "print(tfds.list_builders()) # prints more than 1,000 names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0baeeaf-3ef0-416b-b409-14c2c30509f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "ds = tfds.load(\"mnist\", split=\"train\", shuffle_files=True)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5721be96-46cb-45ee-8ac0-26a455c033f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1345 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.0662 - val_sparse_categorical_accuracy: 0.9795\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9810 - val_loss: 0.0569 - val_sparse_categorical_accuracy: 0.9819\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.0503 - val_sparse_categorical_accuracy: 0.9833\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0364 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0493 - val_sparse_categorical_accuracy: 0.9841\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0304 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0423 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0259 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0423 - val_sparse_categorical_accuracy: 0.9860\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.0404 - val_sparse_categorical_accuracy: 0.9876\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.0399 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.0437 - val_sparse_categorical_accuracy: 0.9854\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0411 - val_sparse_categorical_accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243cad061c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In particular, this dataset has the data instances (images)\n",
    "# in a numpy array of shapes (28,28,1), and the targets (labels) are scalars.\n",
    "# With minor polishing, the data is ready for use in the Keras fit() function. An example is as follows:\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Read data with train-test split\n",
    "ds_train, ds_test = tfds.load(\"mnist\", split=['train', 'test'],\n",
    "                              shuffle_files=True, as_supervised=True)\n",
    "\n",
    "# Set up BatchDataset from the OptionsDataset object\n",
    "ds_train = ds_train.batch(32)\n",
    "ds_test = ds_test.batch(32)\n",
    "\n",
    "# Build LeNet5 model and fit\n",
    "model = Sequential([\n",
    "    Conv2D(6, (5,5), input_shape=(28,28,1), padding=\"same\", activation=\"tanh\"),\n",
    "    AveragePooling2D((2,2), strides=2),\n",
    "    Conv2D(16, (5,5), activation=\"tanh\"),\n",
    "    AveragePooling2D((2,2), strides=2),\n",
    "    Conv2D(120, (5,5), activation=\"tanh\"),\n",
    "    Flatten(),\n",
    "    Dense(84, activation=\"tanh\"),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "earlystopping = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "model.fit(ds_train, validation_data=ds_test, epochs=100, callbacks=[earlystopping])\n",
    "\n",
    "\n",
    "# If we provided as_supervised=True, the dataset would be\n",
    "# records of tuples (features, targets) instead of the dictionary. \n",
    "# It is required for Keras. Moreover, to use the dataset in the fit() function, \n",
    "# we need to create an iterable of batches. This is done by setting up the \n",
    "# batch size of the dataset to convert it from OptionsDataset object into BatchDataset object.\n",
    "# We applied the LeNet5 model for the image classification. But since the target in the dataset \n",
    "# is a numerical value (0 to 9) rather than a Boolean vector, we ask Keras to convert the softmax\n",
    "# output vector into a number before computing accuracy and loss by specifying sparse_categorical_accuracy\n",
    "# and sparse_categorical_crossentropy in the compile() function.\n",
    "# The key here is to understand every dataset is in a different shape.\n",
    "# When you use it with your TensorFlow model, you need to adapt your model to fit the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
